{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- dec tree, or RF, or log reg?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Since what I'm most interested in is which factors are most associated with whether an issue is unresolved, random forests seems like the most appropriate model choice, since I can look at the variable importance plot.\n",
    "\n",
    "Logistic regression is a close second; random forests usually have better performance.\n",
    "\n",
    "Random forests can also do a better job at getting signal out of raw lat and long. For logistic regression, there would need to be a linear relationship between lat and long and the log-odds of the issue being unresolved, which is a taller order.\n",
    "\n",
    "Thinking about my engineered feature `days_from_feb_2016` for example, Logistic Regression wouldn't do a good job with it, but a tree-based model would."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "from datetime import timedelta, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 5\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(786867, 36)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('../data/data_w_transformed_census_and_removed_invalid_rows_and_cols.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>905425</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>REASON</th>\n",
       "      <td>Street Cleaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TYPE</th>\n",
       "      <td>Request for Snow Plowing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SubmittedPhoto</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighborhood</th>\n",
       "      <td>Dorchester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOCATION_ZIPCODE</th>\n",
       "      <td>2124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Property_Type</th>\n",
       "      <td>Address</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LATITUDE</th>\n",
       "      <td>42.2809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LONGITUDE</th>\n",
       "      <td>-71.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source</th>\n",
       "      <td>Citizens Connect App</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_white</th>\n",
       "      <td>0.242399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_black</th>\n",
       "      <td>0.514358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_asian</th>\n",
       "      <td>0.035473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_hispanic</th>\n",
       "      <td>0.0675676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_other</th>\n",
       "      <td>0.140203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poverty_pop_below_poverty_level</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poverty_pop_w_public_assistance</th>\n",
       "      <td>0.0597484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poverty_pop_w_food_stamps</th>\n",
       "      <td>0.138365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poverty_pop_w_ssi</th>\n",
       "      <td>0.0597484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school</th>\n",
       "      <td>15_hs_diploma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedroom</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rent</th>\n",
       "      <td>1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>112500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_issue_unresolved</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_from_feb_2016</th>\n",
       "      <td>-342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_snow_in_type</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   905425\n",
       "REASON                                    Street Cleaning\n",
       "TYPE                             Request for Snow Plowing\n",
       "SubmittedPhoto                                       True\n",
       "neighborhood                                   Dorchester\n",
       "LOCATION_ZIPCODE                                     2124\n",
       "Property_Type                                     Address\n",
       "LATITUDE                                          42.2809\n",
       "LONGITUDE                                         -71.068\n",
       "Source                               Citizens Connect App\n",
       "race_white                                       0.242399\n",
       "race_black                                       0.514358\n",
       "race_asian                                       0.035473\n",
       "race_hispanic                                   0.0675676\n",
       "race_other                                       0.140203\n",
       "poverty_pop_below_poverty_level                         0\n",
       "poverty_pop_w_public_assistance                 0.0597484\n",
       "poverty_pop_w_food_stamps                        0.138365\n",
       "poverty_pop_w_ssi                               0.0597484\n",
       "school                                      15_hs_diploma\n",
       "housing                                               own\n",
       "bedroom                                                 3\n",
       "value                                              350000\n",
       "rent                                                 1750\n",
       "income                                             112500\n",
       "is_issue_unresolved                                 False\n",
       "days_from_feb_2016                                   -342\n",
       "is_snow_in_type                                      True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.TARGET_DT.head(100).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.LOCATION_ZIPCODE.head(100).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.race_white.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.poverty_pop_w_ssi.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['days_from_feb_2016'] = (datetime(year=2016, month=2, day=1) - df.OPEN_DT).map(lambda x: x.days)\n",
    "df['LOCATION_ZIPCODE'] = df['LOCATION_ZIPCODE'].astype('object').fillna('other')\n",
    "df['neighborhood'] = df['neighborhood'].fillna('other')\n",
    "df['is_snow_in_type'] = df.TYPE.map(lambda txt: 'snow' in txt.lower())\n",
    "df['Property_Type'] = df['Property_Type'].fillna('other')\n",
    "# df['race_majority'] = df[[i for i in df.columns if 'race' in i]].idxmax(axis=1) # not useful bc will be dummified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(\n",
    "    ['OPEN_DT',\n",
    "     'TARGET_DT',\n",
    "     'CLOSED_DT',\n",
    "     'COMPLETION_TIME',\n",
    "     'Property_ID',\n",
    "     'LOCATION_STREET_NAME',\n",
    "     'CASE_TITLE',\n",
    "     'CASE_ENQUIRY_ID',\n",
    "     'SUBJECT',\n",
    "     'Department',\n",
    "     'tract_and_block_group'\n",
    "    ], \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(716310, 27)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TODO: make my own zipcode and neighborhood mappings to Census block groups so I can input them into my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>REASON</th>\n",
       "      <td>Signs &amp; Signals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TYPE</th>\n",
       "      <td>Sign Repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SubmittedPhoto</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighborhood</th>\n",
       "      <td>Downtown / Financial District</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOCATION_ZIPCODE</th>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Property_Type</th>\n",
       "      <td>Intersection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LATITUDE</th>\n",
       "      <td>42.3537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LONGITUDE</th>\n",
       "      <td>-71.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source</th>\n",
       "      <td>Constituent Call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_white</th>\n",
       "      <td>0.77619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_black</th>\n",
       "      <td>0.0904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_asian</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_hispanic</th>\n",
       "      <td>0.0666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_other</th>\n",
       "      <td>0.0666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poverty_pop_below_poverty_level</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poverty_pop_w_public_assistance</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poverty_pop_w_food_stamps</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poverty_pop_w_ssi</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school</th>\n",
       "      <td>20_bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <td>rent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedroom</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rent</th>\n",
       "      <td>2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_issue_unresolved</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_from_feb_2016</th>\n",
       "      <td>821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_snow_in_type</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             0\n",
       "REASON                                         Signs & Signals\n",
       "TYPE                                               Sign Repair\n",
       "SubmittedPhoto                                           False\n",
       "neighborhood                     Downtown / Financial District\n",
       "LOCATION_ZIPCODE                                         other\n",
       "Property_Type                                     Intersection\n",
       "LATITUDE                                               42.3537\n",
       "LONGITUDE                                              -71.058\n",
       "Source                                        Constituent Call\n",
       "race_white                                             0.77619\n",
       "race_black                                           0.0904762\n",
       "race_asian                                                   0\n",
       "race_hispanic                                        0.0666667\n",
       "race_other                                           0.0666667\n",
       "poverty_pop_below_poverty_level                              0\n",
       "poverty_pop_w_public_assistance                              0\n",
       "poverty_pop_w_food_stamps                                    0\n",
       "poverty_pop_w_ssi                                            0\n",
       "school                                            20_bachelors\n",
       "housing                                                   rent\n",
       "bedroom                                                      2\n",
       "value                                                   875000\n",
       "rent                                                      2750\n",
       "income                                                  250000\n",
       "is_issue_unresolved                                      False\n",
       "days_from_feb_2016                                         821\n",
       "is_snow_in_type                                          False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummifying bc sklearn's random forest implementation doesn't accept string values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dummify(df, column):\n",
    "    # from Darren's linear regression slides\n",
    "    print '{} is your baseline'.format(sorted(df[column].unique())[-1])\n",
    "    dummy = pd.get_dummies(df[column]).rename(columns=lambda x: column+'_'+str(x)).iloc[:,0:len(df[column].unique())-1]\n",
    "    df = df.drop(column,axis=1) #Why not inplace? because if we do inplace, it will affect the df directly\n",
    "    return pd.concat([df,dummy],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoning is your baseline\n",
      "other is your baseline\n",
      "other is your baseline\n",
      "other is your baseline\n",
      "Twitter is your baseline\n",
      "8_6th_grade is your baseline\n",
      "rent is your baseline\n",
      "Weights and Measures is your baseline\n"
     ]
    }
   ],
   "source": [
    "df1 = dummify(df, 'TYPE')\n",
    "df2 = dummify(df1, 'neighborhood')\n",
    "df3 = dummify(df2, 'LOCATION_ZIPCODE')\n",
    "df4 = dummify(df3, 'Property_Type')\n",
    "df5 = dummify(df4, 'Source')\n",
    "df6 = dummify(df5, 'school')\n",
    "df7 = dummify(df6, 'housing')\n",
    "df8 = dummify(df7, 'REASON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(716310, 356)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REASON                             0\n",
       "TYPE                               0\n",
       "SubmittedPhoto                     0\n",
       "neighborhood                       0\n",
       "LOCATION_ZIPCODE                   0\n",
       "Property_Type                      0\n",
       "LATITUDE                           0\n",
       "LONGITUDE                          0\n",
       "Source                             0\n",
       "race_white                         0\n",
       "race_black                         0\n",
       "race_asian                         0\n",
       "race_hispanic                      0\n",
       "race_other                         0\n",
       "poverty_pop_below_poverty_level    0\n",
       "poverty_pop_w_public_assistance    0\n",
       "poverty_pop_w_food_stamps          0\n",
       "poverty_pop_w_ssi                  0\n",
       "school                             0\n",
       "housing                            0\n",
       "bedroom                            0\n",
       "value                              0\n",
       "rent                               0\n",
       "income                             0\n",
       "is_issue_unresolved                0\n",
       "days_from_feb_2016                 0\n",
       "is_snow_in_type                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OK, let's put it into the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cross_validation import ShuffleSplit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data first between train and test, 80/20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df8.drop('is_issue_unresolved', axis=1), \n",
    "    df8.is_issue_unresolved, \n",
    "    test_size=0.2, \n",
    "    random_state=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    RandomForestClassifier(\n",
    "        bootstrap=True, \n",
    "        class_weight='balanced_subsample', \n",
    "        n_estimators=10\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(X_train.shape[0], n_iter=1, test_size=0.2, random_state=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.3min finished\n"
     ]
    }
   ],
   "source": [
    "params = {'randomforestclassifier__max_depth': [10, 20],\n",
    "      'randomforestclassifier__min_samples_leaf': [101, 1001], # odd for bin class, to avoid ties, 1% of num_rows for max bound\n",
    "} # taking too long\n",
    "\n",
    "params = {'randomforestclassifier__max_depth': [10],\n",
    "      'randomforestclassifier__min_samples_leaf': [1001], # odd for bin class, to avoid ties, 1% of num_rows for max bound\n",
    "} # Brad said hyperparams don't matter _that_ much for RF\n",
    "\n",
    "model = GridSearchCV(pipe, param_grid=params, n_jobs=-1, cv=cv, verbose=True)\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TODO: don't need to do cross-validation w bagging; can use OOB samples, and the random subset of feats in RF replaces CV\n",
    "\n",
    "# http://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html\n",
    "\n",
    "I can also prolly make the above faster my find the # of trees/estimators it takes to converge, and use that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the performance of our best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ...,  True, False,  True], dtype=bool)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[106477,  36795],\n",
       "       [  2508,  11594]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importances = pd.np.argsort(model.feature_importances_)\n",
    "print \"12: top five:\", list(df.columns[feature_importances[-1:-6:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 13. Calculate the standard deviation for feature importances across all trees\n",
    "\n",
    "n = 10 # top 10 features\n",
    "\n",
    "importances = model.feature_importances_[:n]\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(n):\n",
    "    print(\"%d. %s (%f)\" % (f + 1, features[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(10), importances[indices], yerr=std[indices], color=\"r\", align=\"center\")\n",
    "plt.xticks(range(10), indices)\n",
    "plt.xlim([-1, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(model.cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If my best model included 40 trees, was that enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.cv_results_['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make variable importance graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A downside of this graph is that highly correlated features will split importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Logistic Regression with L2 Lasso Regularization\n",
    "\n",
    "which is my favorite way to do feature subset selection at the moment :)\n",
    "\n",
    "There are probably issues when features are co-linear. I'll need to read up on this."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NB: for time-saving purposes, I'll just stick with RFs atm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://nbviewer.jupyter.org/github/JWarmenhoven/ISLR-python/blob/master/Notebooks/Chapter%206.ipynb#6.6.2-The-Lasso\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso = Lasso(max_iter=10000)\n",
    "coefs = []\n",
    "\n",
    "for a in alphas*2:\n",
    "    lasso.set_params(alpha=a)\n",
    "    lasso.fit(scale(X_train), y_train)\n",
    "    coefs.append(lasso.coef_)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas*2, coefs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.axis('tight')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Lasso coefficients as a function of the regularization');"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
