{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- dec tree, or RF, or log reg?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Since what I'm most interested in is which factors are most associated with whether an issue is unresolved, random forests seems like the most appropriate model choice, since I can look at the variable importance plot.\n",
    "\n",
    "Logistic regression is a close second; random forests usually have better performance.\n",
    "\n",
    "Random forests can also do a better job at getting signal out of raw lat and long. For logistic regression, there would need to be a linear relationship between lat and long and the log-odds of the issue being unresolved, which is a taller order.\n",
    "\n",
    "Thinking about my engineered feature `days_from_feb_2016` for example, Logistic Regression wouldn't do a good job with it, but a tree-based model would."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "from datetime import timedelta, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 5\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(716310, 36)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('../data/data_w_transformed_census_and_removed_invalid_rows_and_cols.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.TARGET_DT.head(100).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.LOCATION_ZIPCODE.head(100).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['days_from_feb_2016'] = (datetime(year=2016, month=2, day=1) - df.OPEN_DT).map(lambda x: x.days)\n",
    "df['LOCATION_ZIPCODE'] = df['LOCATION_ZIPCODE'].astype('object').fillna('other')\n",
    "df['neighborhood'] = df['neighborhood'].fillna('other')\n",
    "df['is_snow_in_type'] = df.TYPE.map(lambda txt: 'snow' in txt.lower())\n",
    "# df['race_majority'] = df[[i for i in df.columns if 'race' in i]].idxmax(axis=1) # not useful bc will be dummified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(\n",
    "    ['OPEN_DT',\n",
    "     'TARGET_DT',\n",
    "     'CLOSED_DT',\n",
    "     'COMPLETION_TIME',\n",
    "     'Property_ID',\n",
    "     'LOCATION_STREET_NAME',\n",
    "     'CASE_TITLE',\n",
    "     'CASE_ENQUIRY_ID',\n",
    "     'SUBJECT',\n",
    "     'Department',\n",
    "     'tract_and_block_group'\n",
    "    ], \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(716310, 27)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TODO: make my own zipcode and neighborhood mappings to Census block groups so I can input them into my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>REASON</th>\n",
       "      <td>Signs &amp; Signals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TYPE</th>\n",
       "      <td>Sign Repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SubmittedPhoto</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighborhood</th>\n",
       "      <td>Downtown / Financial District</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOCATION_ZIPCODE</th>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Property_Type</th>\n",
       "      <td>Intersection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LATITUDE</th>\n",
       "      <td>42.3537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LONGITUDE</th>\n",
       "      <td>-71.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source</th>\n",
       "      <td>Constituent Call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_white</th>\n",
       "      <td>0.77619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_black</th>\n",
       "      <td>0.0904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_asian</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_hispanic</th>\n",
       "      <td>0.0666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_other</th>\n",
       "      <td>0.0666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poverty_pop_below_poverty_level</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poverty_pop_w_public_assistance</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poverty_pop_w_food_stamps</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poverty_pop_w_ssi</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school</th>\n",
       "      <td>20_bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <td>rent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedroom</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rent</th>\n",
       "      <td>2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_issue_unresolved</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_from_feb_2016</th>\n",
       "      <td>821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_snow_in_type</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             0\n",
       "REASON                                         Signs & Signals\n",
       "TYPE                                               Sign Repair\n",
       "SubmittedPhoto                                           False\n",
       "neighborhood                     Downtown / Financial District\n",
       "LOCATION_ZIPCODE                                         other\n",
       "Property_Type                                     Intersection\n",
       "LATITUDE                                               42.3537\n",
       "LONGITUDE                                              -71.058\n",
       "Source                                        Constituent Call\n",
       "race_white                                             0.77619\n",
       "race_black                                           0.0904762\n",
       "race_asian                                                   0\n",
       "race_hispanic                                        0.0666667\n",
       "race_other                                           0.0666667\n",
       "poverty_pop_below_poverty_level                              0\n",
       "poverty_pop_w_public_assistance                              0\n",
       "poverty_pop_w_food_stamps                                    0\n",
       "poverty_pop_w_ssi                                            0\n",
       "school                                            20_bachelors\n",
       "housing                                                   rent\n",
       "bedroom                                                      2\n",
       "value                                                   875000\n",
       "rent                                                      2750\n",
       "income                                                  250000\n",
       "is_issue_unresolved                                      False\n",
       "days_from_feb_2016                                         821\n",
       "is_snow_in_type                                          False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummifying bc sklearn's random forest implementation doesn't accept string values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dummify(df, column):\n",
    "    # from Darren's linear regression slides\n",
    "    print '{} is your baseline'.format(sorted(df[column].unique())[-1])\n",
    "    dummy = pd.get_dummies(df[column]).rename(columns=lambda x: column+'_'+str(x)).iloc[:,0:len(df[column].unique())-1]\n",
    "    df = df.drop(column,axis=1) #Why not inplace? because if we do inplace, it will affect the df directly\n",
    "    return pd.concat([df,dummy],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoning is your baseline\n",
      "other is your baseline\n",
      "other is your baseline\n",
      "Intersection is your baseline\n",
      "Twitter is your baseline\n",
      "8_6th_grade is your baseline\n",
      "rent is your baseline\n"
     ]
    }
   ],
   "source": [
    "df1 = dummify(df, 'TYPE')\n",
    "df2 = dummify(df1, 'neighborhood')\n",
    "df3 = dummify(df2, 'LOCATION_ZIPCODE')\n",
    "df4 = dummify(df3, 'Property_Type')\n",
    "df5 = dummify(df4, 'Source')\n",
    "df6 = dummify(df5, 'school')\n",
    "df7 = dummify(df6, 'housing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(716310, 302)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OK, let's put it into the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data first between train and test, 80/20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop('is_issue_unresolved', axis=1), \n",
    "    df.is_issue_unresolved, \n",
    "    test_size=0.2, \n",
    "    random_state=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    RandomForestClassifier(\n",
    "        bootstrap=True, \n",
    "        class_weight='balanced_subsample', \n",
    "        n_estimators=10\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 326, in _handle_workers\n",
      "    pool._maintain_pool()\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 230, in _maintain_pool\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/multiprocessing/pool.py\", line 223, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/multiprocessing/process.py\", line 130, in start\n",
      "    self._popen = Popen(self)\n",
      "  File \"/home/ubuntu/anaconda2/lib/python2.7/multiprocessing/forking.py\", line 121, in __init__\n",
      "    self.pid = os.fork()\n",
      "OSError: [Errno 12] Cannot allocate memory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {'randomforestclassifier__max_depth': [10, 20],\n",
    "      'randomforestclassifier__min_samples_leaf': [101, 1001], # odd for bin class, to avoid ties, 1% of num_rows for max bound\n",
    "}\n",
    "\n",
    "model = GridSearchCV(pipe, param_grid=params, n_jobs=-1, cv=5, verbose=True)\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TODO: don't need to do cross-validation w bagging; can use OOB samples, and the random subset of feats in RF replaces CV\n",
    "\n",
    "# http://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html\n",
    "\n",
    "I can also prolly make the above faster my find the # of trees/estimators it takes to converge, and use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(model.cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If my best model included 40 trees, was that enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.cv_results_['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make variable importance graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A downside of this graph is that highly correlated features will split importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Logistic Regression with L2 Lasso Regularization\n",
    "\n",
    "which is my favorite way to do feature subset selection at the moment :)\n",
    "\n",
    "There are probably issues when features are co-linear. I'll need to read up on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://nbviewer.jupyter.org/github/JWarmenhoven/ISLR-python/blob/master/Notebooks/Chapter%206.ipynb#6.6.2-The-Lasso\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso = Lasso(max_iter=10000)\n",
    "coefs = []\n",
    "\n",
    "for a in alphas*2:\n",
    "    lasso.set_params(alpha=a)\n",
    "    lasso.fit(scale(X_train), y_train)\n",
    "    coefs.append(lasso.coef_)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas*2, coefs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.axis('tight')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Lasso coefficients as a function of the regularization');"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
