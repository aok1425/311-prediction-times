{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Now that I know that my submodels perform a bit better than the model on the entire dataset, I can take advantage of the submodels and find the coefficients that are most associated with response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CATEGORY_GROUPS_IN_QUESTION = [['Pick up Dead Animal'],\n",
    "['Abandoned Vehicles', 'Abandoned Bicycle'],\n",
    "['Rodent Activity',\t'Bed Bugs', 'Mice Infestation - Residential'],\n",
    "['Sidewalk Repair', 'Sidewalk Repair (Make Safe)'],\n",
    "['Needle Pickup'],\n",
    "['Unsatisfactory Living Conditions', 'Poor Conditions of Property', 'Unsanitary Conditions - Establishment', 'Illegal Occupancy', 'Heat - Excessive  Insufficient'],\n",
    "['Request for Pothole Repair'],\n",
    "['Graffiti Removal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Does this have statistically significant coefs, assuming homoskedacity and a linear predictor-response relationship and Normalized residuals and imperfect collinearity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/datascientist/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "rcParams['figure.figsize'] = 20, 5\n",
    "\n",
    "import os, sys\n",
    "sys.path.append(os.path.join(os.path.dirname('.'), \"../../preprocessing\"))\n",
    "sys.path.append(os.path.join(os.path.dirname('.'), \"..\"))\n",
    "from helper_functions import dummify_cols_and_baselines, make_alphas, remove_outliers_by_type, adjusted_r2, transform_school, get_vifs\n",
    "\n",
    "from utilities import remove_one_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(516406, 40)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig = pd.read_pickle('../../data/data_from_remove_from_dataset.pkl')\n",
    "df_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../preprocessing/helper_functions.py:58: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  df.school = df.school.str.extract(r'(\\d\\d?)').astype(int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(516406, 40)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig = transform_school(df_orig)\n",
    "df_orig.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filterering by `TYPE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pick up Dead Animal']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7454, 40)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "print CATEGORY_GROUPS_IN_QUESTION[i]\n",
    "df_orig = df_orig[df_orig.TYPE.isin(CATEGORY_GROUPS_IN_QUESTION[i])]\n",
    "df_orig.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing outliers\n",
    "\n",
    "A standard procedure is to remove values further than 3 standard deviations from the mean. Since I have so many low values and some very high values, I anecdotally think that the low values are very likely to be true, and the high values not so much.\n",
    "\n",
    "So, I will remove values further than 3 SDs from the median, by type.\n",
    "\n",
    "Ideally, I would take into account the time dimension. I would like to do so given more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7372, 40)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outliers_removed = remove_outliers_by_type(df_orig, y_col='COMPLETION_HOURS_LOG_10')\n",
    "df_outliers_removed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove `TYPE` col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_outliers_removed.drop('TYPE', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "['race_black',\n",
    " 'race_other',\n",
    " 'earned_income_per_capita',\n",
    " 'poverty_pop_w_public_assistance',\n",
    " 'poverty_pop_w_ssi',\n",
    " 'bedroom',\n",
    " 'bedroom_std_dev',\n",
    " 'value_std_dev',\n",
    " 'rent',\n",
    " 'income',\n",
    " 'is_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_orig_dataset = ['COMPLETION_HOURS_LOG_10', 'SubmittedPhoto']\n",
    "cols_census = [\n",
    "     'poverty_pop_below_poverty_level',\n",
    "]\n",
    "cols_engineered = ['queue_wk', 'queue_wk_open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7372, 5)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_outliers_removed[cols_orig_dataset + cols_census + cols_engineered]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing NAs for cols like `school_std_dev`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: index, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "aa = df.isnull().any().reset_index()\n",
    "nas = aa[aa[0] == True]['index']\n",
    "print nas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7372, 5)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a bad temporary band-aid\n",
    "df = df.dropna(subset=nas.tolist())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_dummify = [i for i in df.dtypes[df.dtypes == object].index if i != 'TYPE']\n",
    "cols_to_dummify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dummified, baseline_cols = dummify_cols_and_baselines(df, cols_to_dummify, chosen_col_i=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7372, 5)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummified.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>905400</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COMPLETION_HOURS_LOG_10</th>\n",
       "      <td>0.0124857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SubmittedPhoto</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poverty_pop_below_poverty_level</th>\n",
       "      <td>0.262473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rent_std_dev</th>\n",
       "      <td>0.0878398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income_std_dev</th>\n",
       "      <td>0.0461804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queue_wk</th>\n",
       "      <td>12873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queue_wk_open</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    905400\n",
       "COMPLETION_HOURS_LOG_10          0.0124857\n",
       "SubmittedPhoto                       False\n",
       "poverty_pop_below_poverty_level   0.262473\n",
       "rent_std_dev                     0.0878398\n",
       "income_std_dev                   0.0461804\n",
       "queue_wk                             12873\n",
       "queue_wk_open                            1"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummified.head(1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "poverty_pop_w_food_stamps          4.003574\n",
       "race_black                         3.204188\n",
       "poverty_pop_below_poverty_level    3.189694\n",
       "earned_income_per_capita           3.176380\n",
       "income                             2.522978\n",
       "race_hispanic                      2.204418\n",
       "school                             1.954809\n",
       "poverty_pop_w_ssi                  1.857534\n",
       "school_std_dev                     1.718347\n",
       "rent_std_dev                       1.688859\n",
       "queue_wk                           1.651506\n",
       "housing_std_dev                    1.645407\n",
       "race_asian                         1.581442\n",
       "value_std_dev                      1.535014\n",
       "poverty_pop_w_public_assistance    1.485504\n",
       "income_std_dev                     1.480597\n",
       "rent                               1.435624\n",
       "bedroom                            1.417223\n",
       "Source_Citizens Connect App        1.386203\n",
       "queue_wk_open                      1.362655\n",
       "value                              1.344422\n",
       "bedroom_std_dev                    1.152301\n",
       "race_other                         1.122180\n",
       "Property_Type_Address              1.041356\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_vifs(df_dummified.drop(['SubmittedPhoto', 'is_description'], axis=1), 'COMPLETION_HOURS_LOG_10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import string\n",
    "from StringIO import StringIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_dummified.drop('COMPLETION_HOURS_LOG_10', axis=1), \n",
    "    df_dummified.COMPLETION_HOURS_LOG_10, \n",
    "    test_size=0.2, \n",
    "    random_state=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use LassoCV to find col subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), LassoCV())\n",
    "cv = ShuffleSplit(X_train.shape[0], n_iter=1, test_size=0.2, random_state=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.0180734</td>\n",
       "      <td>0.0183029</td>\n",
       "      <td>0.0171696</td>\n",
       "      <td>0.00765176</td>\n",
       "      <td>-0.00271772</td>\n",
       "      <td>-0.00271772</td>\n",
       "      <td>-0.00271772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>0.0202094</td>\n",
       "      <td>0.0189817</td>\n",
       "      <td>0.0155542</td>\n",
       "      <td>0.00732475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_lassocv__alphas</th>\n",
       "      <td>[0.001]</td>\n",
       "      <td>[0.003]</td>\n",
       "      <td>[0.01]</td>\n",
       "      <td>[0.03]</td>\n",
       "      <td>[0.1]</td>\n",
       "      <td>[0.3]</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0          1          2           3  \\\n",
       "mean_test_score        0.0180734  0.0183029  0.0171696  0.00765176   \n",
       "mean_train_score       0.0202094  0.0189817  0.0155542  0.00732475   \n",
       "param_lassocv__alphas    [0.001]    [0.003]     [0.01]      [0.03]   \n",
       "\n",
       "                                4           5           6  \n",
       "mean_test_score       -0.00271772 -0.00271772 -0.00271772  \n",
       "mean_train_score                0           0           0  \n",
       "param_lassocv__alphas       [0.1]       [0.3]       [1.0]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'lassocv__alphas': make_alphas(-3, 0)}\n",
    "# params = {'lassocv__alphas': make_alphas(-2, -2)}\n",
    "model = GridSearchCV(pipe, param_grid=params, n_jobs=1, cv=cv, verbose=0)\n",
    "model.fit(X_train, y_train)\n",
    "pd.DataFrame(model.cv_results_).T.iloc[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lassocv__alphas': [0.0030000000000000001]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11 cols go to zero out of 26'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{} cols go to zero out of {}'.format(\n",
    "    len(X_train.columns[model.best_estimator_.steps[-1][-1].coef_ == 0]),\n",
    "    len(X_train.columns)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['race_black',\n",
       " 'race_other',\n",
       " 'earned_income_per_capita',\n",
       " 'poverty_pop_w_public_assistance',\n",
       " 'poverty_pop_w_ssi',\n",
       " 'bedroom',\n",
       " 'bedroom_std_dev',\n",
       " 'value_std_dev',\n",
       " 'rent',\n",
       " 'income',\n",
       " 'is_description']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_zero = list(X_train.columns[model.best_estimator_.steps[-1][-1].coef_ == 0])\n",
    "cols_zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use subsetted cols to run lin reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dummified.columns = [col.translate(None, string.punctuation).replace(' ', '') if col != 'COMPLETION_HOURS_LOG_10' else col for col in df_dummified.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_dummified.drop(['COMPLETION_HOURS_LOG_10'], axis=1), \n",
    "    df_dummified.COMPLETION_HOURS_LOG_10, \n",
    "    test_size=0.2, \n",
    "    random_state=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col_list = ' + '.join(df_dummified.drop(['COMPLETION_HOURS_LOG_10'], axis=1).columns)\n",
    "\n",
    "est = smf.ols(\n",
    "    'COMPLETION_HOURS_LOG_10 ~ {}'.format(col_list), \n",
    "    pd.concat([X_train, y_train], axis=1)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>COMPLETION_HOURS_LOG_10</td> <th>  R-squared:         </th> <td>   0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                      <td>OLS</td>           <th>  Adj. R-squared:    </th> <td>   0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>Least Squares</td>      <th>  F-statistic:       </th> <td>   28.71</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                <td>Sat, 04 Mar 2017</td>     <th>  Prob (F-statistic):</th> <td>1.16e-23</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                    <td>14:40:28</td>         <th>  Log-Likelihood:    </th> <td> -4891.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>         <td>  5897</td>          <th>  AIC:               </th> <td>   9792.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>             <td>  5892</td>          <th>  BIC:               </th> <td>   9826.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>                 <td>     4</td>          <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>nonrobust</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.summary().tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting adjusted $R^2$ on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = est.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020443590379377725"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_r2(y_test, y_pred, num_features=X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57095618044238183"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting model\n",
    "\n",
    "Which features are most associated with completion time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 8)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.read_csv(StringIO(est.summary().tables[1].as_csv()), index_col=0).reset_index()\n",
    "df_results.columns = ['coef_name'] + [i.rstrip().lstrip() for i in df_results.columns][1:]\n",
    "df_results.coef_name = df_results.coef_name.map(lambda x: x.strip())\n",
    "df_results = df_results.sort_values('P>|t|')\n",
    "df_results['pct_diff_for_y'] = (10**df_results.coef - 1) * 100\n",
    "df_results['pct_diff_for_y_abs'] = pd.np.abs((10**df_results.coef - 1) * 100)\n",
    "df_results.sort_values('pct_diff_for_y_abs', inplace=True, ascending=False)\n",
    "df_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef_name</th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>[95.0% Conf. Int.]</th>\n",
       "      <th>pct_diff_for_y</th>\n",
       "      <th>pct_diff_for_y_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>0.440400</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>18.654</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.394     0.487</td>\n",
       "      <td>175.676661</td>\n",
       "      <td>175.676661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SubmittedPhoto[T.True]</td>\n",
       "      <td>0.113000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>4.573</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.065     0.161</td>\n",
       "      <td>29.717927</td>\n",
       "      <td>29.717927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>queuewkopen</td>\n",
       "      <td>-0.001500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.920</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.002    -0.001</td>\n",
       "      <td>-0.344792</td>\n",
       "      <td>0.344792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>queuewk</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-6.814</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-2.06e-05 -1.14e-05</td>\n",
       "      <td>-0.003689</td>\n",
       "      <td>0.003689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>povertypopbelowpovertylevel</td>\n",
       "      <td>-0.104600</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>-2.003</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.207    -0.002</td>\n",
       "      <td>-21.404080</td>\n",
       "      <td>21.404080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     coef_name      coef   std err       t  P>|t|  \\\n",
       "0                    Intercept  0.440400  0.024000  18.654  0.000   \n",
       "1       SubmittedPhoto[T.True]  0.113000  0.025000   4.573  0.000   \n",
       "4                  queuewkopen -0.001500  0.000000  -3.920  0.000   \n",
       "3                      queuewk -0.000016  0.000002  -6.814  0.000   \n",
       "2  povertypopbelowpovertylevel -0.104600  0.052000  -2.003  0.045   \n",
       "\n",
       "    [95.0% Conf. Int.]  pct_diff_for_y  pct_diff_for_y_abs  \n",
       "0      0.394     0.487      175.676661          175.676661  \n",
       "1      0.065     0.161       29.717927           29.717927  \n",
       "4     -0.002    -0.001       -0.344792            0.344792  \n",
       "3  -2.06e-05 -1.14e-05       -0.003689            0.003689  \n",
       "2     -0.207    -0.002      -21.404080           21.404080  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values('P>|t|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef_name</th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>[95.0% Conf. Int.]</th>\n",
       "      <th>pct_diff_for_y</th>\n",
       "      <th>pct_diff_for_y_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>2.405800</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>91.460</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.354     2.457</td>\n",
       "      <td>25356.576639</td>\n",
       "      <td>25356.576639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>isdescription[T.True]</td>\n",
       "      <td>-0.099800</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>-7.336</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.126    -0.073</td>\n",
       "      <td>-20.530588</td>\n",
       "      <td>20.530588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>raceblack</td>\n",
       "      <td>0.072300</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>4.061</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.037     0.107</td>\n",
       "      <td>18.113625</td>\n",
       "      <td>18.113625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>racehispanic</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>2.358</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.012     0.131</td>\n",
       "      <td>17.896252</td>\n",
       "      <td>17.896252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SourceConstituentCall</td>\n",
       "      <td>-0.042800</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>-2.970</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.071    -0.015</td>\n",
       "      <td>-9.385020</td>\n",
       "      <td>9.385020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SourceCitizensConnectApp</td>\n",
       "      <td>-0.039500</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>-2.113</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.076    -0.003</td>\n",
       "      <td>-8.693856</td>\n",
       "      <td>8.693856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>queuewkopen</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>14.848</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001     0.001</td>\n",
       "      <td>0.230524</td>\n",
       "      <td>0.230524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rent</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-2.035</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-3.32e-05  -6.2e-07</td>\n",
       "      <td>-0.003889</td>\n",
       "      <td>0.003889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  coef_name      coef   std err       t  P>|t|  \\\n",
       "0                 Intercept  2.405800  0.026000  91.460  0.000   \n",
       "1     isdescription[T.True] -0.099800  0.014000  -7.336  0.000   \n",
       "2                 raceblack  0.072300  0.018000   4.061  0.000   \n",
       "4              racehispanic  0.071500  0.030000   2.358  0.018   \n",
       "9     SourceConstituentCall -0.042800  0.014000  -2.970  0.003   \n",
       "8  SourceCitizensConnectApp -0.039500  0.019000  -2.113  0.035   \n",
       "7               queuewkopen  0.001000  0.000067  14.848  0.000   \n",
       "6                      rent -0.000017  0.000008  -2.035  0.042   \n",
       "\n",
       "    [95.0% Conf. Int.]  pct_diff_for_y  pct_diff_for_y_abs  \n",
       "0      2.354     2.457    25356.576639        25356.576639  \n",
       "1     -0.126    -0.073      -20.530588           20.530588  \n",
       "2      0.037     0.107       18.113625           18.113625  \n",
       "4      0.012     0.131       17.896252           17.896252  \n",
       "9     -0.071    -0.015       -9.385020            9.385020  \n",
       "8     -0.076    -0.003       -8.693856            8.693856  \n",
       "7      0.001     0.001        0.230524            0.230524  \n",
       "6  -3.32e-05  -6.2e-07       -0.003889            0.003889  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[df_results['P>|t|'] < 0.1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'queuewkopen' can be replaced for 'PropertyTypeAddress', w R2 = .00sth instead of .03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rentstddev', 13),\n",
       " ('SubmittedPhoto', 12.831),\n",
       " ('queuewkopen', 12.765),\n",
       " ('povertypopbelowpovertylevel', 12.239),\n",
       " ('queuewk', 8.798)]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for col in X_train.columns:\n",
    "    if col != 'Intercept':\n",
    "        score = remove_one_feature([col], df_dummified)\n",
    "        scores.append((col, score))\n",
    "        \n",
    "sorted(scores, key=lambda x: x[1])[::-1]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "Most we can say is sign, and then magnitude for comparable coefs. Rank is meaningless, eg for rent vs \"source: mobile app\".\n",
    "\n",
    "All the results are weird.\n",
    "\n",
    "### Weird results\n",
    "- Having more **issues in the queue** is associated with **better** completion time.\n",
    "- Having a higher proportion of **people below the poverty level** is associated with a **better** completion time.\n",
    "- **Submitting a photo** is associated with a **worse** completion time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9390.000000\n",
       "mean      383.803573\n",
       "std       405.297599\n",
       "min         2.275000\n",
       "25%       171.718333\n",
       "50%       307.753611\n",
       "75%       479.439375\n",
       "max      7198.562222\n",
       "Name: COMPLETION_HOURS_LOG_10, dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummified.COMPLETION_HOURS_LOG_10.map(lambda x: 10**x).describe()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
