{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "What happens to performance when we add the features from the original dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.path.dirname('.'), \"../preprocessing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transform_for_num_issues_pred import main as transform_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "rcParams['figure.figsize'] = 20, 5\n",
    "\n",
    "from helper_functions import dummify_cols_and_baselines, make_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(516406, 40)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig = pd.read_pickle('../data/data_from_remove_from_dataset.pkl')\n",
    "df_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../preprocessing/transform_for_num_issues_pred.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_subset['NUM_ISSUES'] = 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(822, 221)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed = transform_dataset(df_orig)\n",
    "df_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_orig_dataset = ['NUM_ISSUES', 'tract_and_block_group', 'SubmittedPhoto', 'Property_Type', 'Source', 'is_description']\n",
    "cols_type = [col for col in df_transformed.columns if 'TYPE' in col]\n",
    "cols_census = ['race_white',\n",
    "     'race_black',\n",
    "     'race_asian',\n",
    "     'race_hispanic',\n",
    "     'race_other',\n",
    "     'poverty_pop_below_poverty_level',\n",
    "     'earned_income_per_capita',\n",
    "     'poverty_pop_w_public_assistance',\n",
    "     'poverty_pop_w_food_stamps',\n",
    "     'poverty_pop_w_ssi',\n",
    "     'school',\n",
    "     'school_std_dev',\n",
    "     'housing',\n",
    "     'housing_std_dev',\n",
    "     'bedroom',\n",
    "     'bedroom_std_dev',\n",
    "     'value',\n",
    "     'value_std_dev',\n",
    "     'rent',\n",
    "     'rent_std_dev',\n",
    "     'income',\n",
    "     'income_std_dev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(822, 219)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_col_subset = df_transformed[cols_orig_dataset + cols_type + cols_census]\n",
    "# df_col_subset = df_transformed[cols_orig_dataset + cols_census]\n",
    "# df_col_subset = df_transformed[cols_census + ['NUM_ISSUES']]\n",
    "# df_col_subset = df_transformed[cols_census + ['NUM_ISSUES', 'tract_and_block_group'] + cols_type]\n",
    "\n",
    "df_col_subset.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# I will do the simple and incorrect thing and drop the NAs\n",
    "# In reality, there is a discrepancy btwn census block group\n",
    "# and imputed zipcode via kNN.\n",
    "# TODO: write a fn in add_to_dataset that cleans zipcode and\n",
    "# neighborhood_from_zip so that for a given Census block group\n",
    "# it's the majority ones.\n",
    "# The bad thing about this is that I'll now miss X Census block groups for my map + predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550, 219)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_col_subset.dropna().drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing outliers\n",
    "\n",
    "0303003 is City Hall, which is where issues are assigned to when they don't have a location. Ideally, I would find out which issues truly took place in that block group and filter accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[df.tract_and_block_group != '0303003'].drop('tract_and_block_group', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Property_Type', u'Source', u'school', u'housing'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_dummify = df.dtypes[df.dtypes == object].index\n",
    "cols_to_dummify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection is baseline 0 4\n",
      "Constituent Call is baseline 1 4\n",
      "8_6th_grade is baseline 2 4\n",
      "rent is baseline 3 4\n"
     ]
    }
   ],
   "source": [
    "df_dummified, baseline_cols = dummify_cols_and_baselines(df, cols_to_dummify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(549, 227)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_dummified = df_dummified.drop('race_other', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUM_ISSUES</th>\n",
       "      <th>SubmittedPhoto</th>\n",
       "      <th>is_description</th>\n",
       "      <th>TYPE_ADA</th>\n",
       "      <th>TYPE_Abandoned Bicycle</th>\n",
       "      <th>TYPE_Abandoned Building</th>\n",
       "      <th>TYPE_Abandoned Vehicles</th>\n",
       "      <th>TYPE_Alert Boston</th>\n",
       "      <th>TYPE_Animal Found</th>\n",
       "      <th>TYPE_Animal Generic Request</th>\n",
       "      <th>...</th>\n",
       "      <th>school_11_9th_grade</th>\n",
       "      <th>school_13_11th_grade</th>\n",
       "      <th>school_14_12th_grade_no_diploma</th>\n",
       "      <th>school_15_hs_diploma</th>\n",
       "      <th>school_18_some_college_no_degree</th>\n",
       "      <th>school_19_associates</th>\n",
       "      <th>school_20_bachelors</th>\n",
       "      <th>school_21_masters</th>\n",
       "      <th>school_22_professional_school</th>\n",
       "      <th>housing_own</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>741</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.170608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NUM_ISSUES  SubmittedPhoto  is_description  TYPE_ADA  \\\n",
       "0         741         0.03125        0.170608       0.0   \n",
       "\n",
       "   TYPE_Abandoned Bicycle  TYPE_Abandoned Building  TYPE_Abandoned Vehicles  \\\n",
       "0                     0.0                      0.0                  0.01098   \n",
       "\n",
       "   TYPE_Alert Boston  TYPE_Animal Found  TYPE_Animal Generic Request  \\\n",
       "0                0.0                0.0                     0.000845   \n",
       "\n",
       "      ...       school_11_9th_grade  school_13_11th_grade  \\\n",
       "0     ...                         0                     0   \n",
       "\n",
       "   school_14_12th_grade_no_diploma  school_15_hs_diploma  \\\n",
       "0                                0                     1   \n",
       "\n",
       "   school_18_some_college_no_degree  school_19_associates  \\\n",
       "0                                 0                     0   \n",
       "\n",
       "   school_20_bachelors  school_21_masters  school_22_professional_school  \\\n",
       "0                    0                  0                              0   \n",
       "\n",
       "   housing_own  \n",
       "0            1  \n",
       "\n",
       "[1 rows x 227 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummified.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import make_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_dummified.drop('NUM_ISSUES', axis=1), \n",
    "    df_dummified.NUM_ISSUES, \n",
    "    test_size=0.2, \n",
    "    random_state=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), LassoCV())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse = make_scorer(mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'lassocv__alphas': make_alphas(-10, 5)}\n",
    "params = {'lassocv__alphas': [[30], [100], [300]]}\n",
    "# params = {}\n",
    "model = GridSearchCV(pipe, param_grid=params, n_jobs=-1, cv=10)\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.359371</td>\n",
       "      <td>0.39047</td>\n",
       "      <td>0.177733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0182771</td>\n",
       "      <td>0.0214608</td>\n",
       "      <td>0.00888653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-0.0154139</td>\n",
       "      <td>0.317651</td>\n",
       "      <td>-0.00617079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>0.697868</td>\n",
       "      <td>0.48251</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_lassocv__alphas</th>\n",
       "      <td>[30]</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[300]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0          1           2\n",
       "mean_fit_time           0.359371    0.39047    0.177733\n",
       "mean_score_time        0.0182771  0.0214608  0.00888653\n",
       "mean_test_score       -0.0154139   0.317651 -0.00617079\n",
       "mean_train_score        0.697868    0.48251           0\n",
       "param_lassocv__alphas       [30]      [100]       [300]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model.cv_results_).T.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35469983587882137"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Adding the additional features improves our model's performance, but we are still in an overfit situation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
