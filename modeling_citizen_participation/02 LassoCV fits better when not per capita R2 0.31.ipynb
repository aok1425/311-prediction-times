{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "What happens to performance when we add the features from the original dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.path.dirname('.'), \"../preprocessing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transform_for_num_issues_pred import main as transform_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "rcParams['figure.figsize'] = 20, 5\n",
    "\n",
    "from helper_functions import dummify_cols_and_baselines, make_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(516406, 40)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig = pd.read_pickle('../data/data_from_remove_from_dataset.pkl')\n",
    "df_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../preprocessing/transform_for_num_issues_pred.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_subset['NUM_ISSUES'] = 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(822, 27)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed = transform_dataset(df_orig)\n",
    "df_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tract_and_block_group</th>\n",
       "      <td>1004002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_white</th>\n",
       "      <td>0.242399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_black</th>\n",
       "      <td>0.514358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_asian</th>\n",
       "      <td>0.035473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_hispanic</th>\n",
       "      <td>0.0675676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_other</th>\n",
       "      <td>0.140203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poverty_pop_below_poverty_level</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earned_income_per_capita</th>\n",
       "      <td>34340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poverty_pop_w_public_assistance</th>\n",
       "      <td>0.0597484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poverty_pop_w_food_stamps</th>\n",
       "      <td>0.138365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poverty_pop_w_ssi</th>\n",
       "      <td>0.0597484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode</th>\n",
       "      <td>2124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighborhood_from_zip</th>\n",
       "      <td>Dorchester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school</th>\n",
       "      <td>15_hs_diploma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school_std_dev</th>\n",
       "      <td>91.7672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing_std_dev</th>\n",
       "      <td>26.8701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedroom</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedroom_std_dev</th>\n",
       "      <td>61.5123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value_std_dev</th>\n",
       "      <td>20.9794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rent</th>\n",
       "      <td>1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rent_std_dev</th>\n",
       "      <td>19.1622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>112500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income_std_dev</th>\n",
       "      <td>28.6167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM_ISSUES</th>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM_ISSUES_PER_100_POP</th>\n",
       "      <td>62.5845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             0\n",
       "tract_and_block_group                  1004002\n",
       "race_white                            0.242399\n",
       "race_black                            0.514358\n",
       "race_asian                            0.035473\n",
       "race_hispanic                        0.0675676\n",
       "race_other                            0.140203\n",
       "poverty_pop_below_poverty_level              0\n",
       "earned_income_per_capita                 34340\n",
       "poverty_pop_w_public_assistance      0.0597484\n",
       "poverty_pop_w_food_stamps             0.138365\n",
       "poverty_pop_w_ssi                    0.0597484\n",
       "zipcode                                   2124\n",
       "neighborhood_from_zip               Dorchester\n",
       "school                           15_hs_diploma\n",
       "school_std_dev                         91.7672\n",
       "housing                                    own\n",
       "housing_std_dev                        26.8701\n",
       "bedroom                                      3\n",
       "bedroom_std_dev                        61.5123\n",
       "value                                   350000\n",
       "value_std_dev                          20.9794\n",
       "rent                                      1750\n",
       "rent_std_dev                           19.1622\n",
       "income                                  112500\n",
       "income_std_dev                         28.6167\n",
       "NUM_ISSUES                                 741\n",
       "NUM_ISSUES_PER_100_POP                 62.5845"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed.head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_orig_dataset = ['NUM_ISSUES', 'tract_and_block_group']\n",
    "cols_census = ['race_white',\n",
    "     'race_black',\n",
    "     'race_asian',\n",
    "     'race_hispanic',\n",
    "     'race_other',\n",
    "     'poverty_pop_below_poverty_level',\n",
    "     'earned_income_per_capita',\n",
    "     'poverty_pop_w_public_assistance',\n",
    "     'poverty_pop_w_food_stamps',\n",
    "     'poverty_pop_w_ssi',\n",
    "     'school',\n",
    "     'school_std_dev',\n",
    "     'housing',\n",
    "     'housing_std_dev',\n",
    "     'bedroom',\n",
    "     'bedroom_std_dev',\n",
    "     'value',\n",
    "     'value_std_dev',\n",
    "     'rent',\n",
    "     'rent_std_dev',\n",
    "     'income',\n",
    "     'income_std_dev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(822, 24)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_col_subset = df_transformed[cols_orig_dataset + cols_census]\n",
    "df_col_subset.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# I will do the simple and incorrect thing and drop the NAs\n",
    "# In reality, there is a discrepancy btwn census block group\n",
    "# and imputed zipcode via kNN.\n",
    "# TODO: write a fn in add_to_dataset that cleans zipcode and\n",
    "# neighborhood_from_zip so that for a given Census block group\n",
    "# it's the majority ones.\n",
    "# The bad thing about this is that I'll now miss X Census block groups for my map + predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(558, 24)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_col_subset.dropna().drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing outliers\n",
    "\n",
    "0303003 is City Hall, which is where issues are assigned to when they don't have a location. Ideally, I would find out which issues truly took place in that block group and filter accordingly.\n",
    "\n",
    "The other Census block groups I chose from looking at a Tableau cloropleth map. They are places with few, if any people living there, like parks and in the financial distinct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outliers = ('9818001', '9811003', '9807001', '0303003', '0701018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(553, 23)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[~df.tract_and_block_group.isin(outliers)].drop('tract_and_block_group', axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      822.000000\n",
       "mean      1952.018248\n",
       "std       5419.910281\n",
       "min         50.000000\n",
       "25%        582.250000\n",
       "50%        833.000000\n",
       "75%       1219.000000\n",
       "max      29667.000000\n",
       "Name: NUM_ISSUES, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed.NUM_ISSUES.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     553.000000\n",
       "mean      874.059675\n",
       "std       461.379271\n",
       "min        50.000000\n",
       "25%       580.000000\n",
       "50%       807.000000\n",
       "75%      1101.000000\n",
       "max      3007.000000\n",
       "Name: NUM_ISSUES, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.NUM_ISSUES.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'school', u'housing'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_dummify = df.dtypes[df.dtypes == object].index\n",
    "cols_to_dummify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8_6th_grade is baseline 0 2\n",
      "rent is baseline 1 2\n"
     ]
    }
   ],
   "source": [
    "df_dummified, baseline_cols = dummify_cols_and_baselines(df, cols_to_dummify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(553, 32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_dummified = df_dummified.drop('race_other', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/datascientist/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import make_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_dummified.drop('NUM_ISSUES', axis=1), \n",
    "    df_dummified.NUM_ISSUES, \n",
    "    test_size=0.2, \n",
    "    random_state=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), LassoCV())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse = make_scorer(mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'lassocv__alphas': make_alphas(-5, 5)}\n",
    "params = {'lassocv__alphas': [[3], [10], [30]]}\n",
    "model = GridSearchCV(pipe, param_grid=params, n_jobs=-1, cv=10)\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.0416473</td>\n",
       "      <td>0.0323391</td>\n",
       "      <td>0.0239318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.00138454</td>\n",
       "      <td>0.000985503</td>\n",
       "      <td>0.00100396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.442863</td>\n",
       "      <td>0.451715</td>\n",
       "      <td>0.437078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>0.508133</td>\n",
       "      <td>0.494915</td>\n",
       "      <td>0.464107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_lassocv__alphas</th>\n",
       "      <td>[3]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[30]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0            1           2\n",
       "mean_fit_time           0.0416473    0.0323391   0.0239318\n",
       "mean_score_time        0.00138454  0.000985503  0.00100396\n",
       "mean_test_score          0.442863     0.451715    0.437078\n",
       "mean_train_score         0.508133     0.494915    0.464107\n",
       "param_lassocv__alphas         [3]         [10]        [30]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model.cv_results_).T.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30662264833319364"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interesting coef values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef_values = pd.DataFrame({\n",
    "    'name': X_train.columns,\n",
    "    'coef': model.best_estimator_.steps[-1][-1].coef_\n",
    "})\n",
    "\n",
    "coef_values['abs_coef'] = pd.np.abs(coef_values.coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coef_values[coef_values.coef != 0].sort_values('abs_coef', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Why does the model perform better when we _don't_ transform the # of 311 issues to per capita? \n",
    "\n",
    "One guess is that in areas where there are a high number of issues and low population, like the Financial District, transforming _distorts_ the # of 311 issues. The best denominator would be # of people in the area at 1pm, instead of # of people living there.\n",
    "\n",
    "And perhaps the distribution of population amongst the Census block groups is fairly Uniform? I believe that's how they're decided."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TODO: check if dist of pop in Census blocks is more or less Uniform"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
